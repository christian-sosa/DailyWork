{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import awswrangler as wr\n",
    "import io\n",
    "from datetime import date, datetime\n",
    "\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "response = s3.list_object_versions(Bucket=\"cchc-dw-qa-raw\", Prefix=\"boletin_concursal/\")\n",
    "\n",
    "versions = response[\"Versions\"]\n",
    "\n",
    "path = \"s3://cchc-dw-dev-staging/boletin_concursal/insolvencias/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, version in enumerate(versions):\n",
    "    object = s3.get_object(Bucket=\"cchc-dw-qa-raw\", VersionId=version[\"VersionId\"], Key=version[\"Key\"])\n",
    "    df = pd.read_parquet(io.BytesIO(object[\"Body\"].read()))\n",
    "\n",
    "    particion = version[\"LastModified\"]\n",
    "    df[\"extraction_date\"] = particion.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    df[\"year\"] = particion.year\n",
    "    df[\"month\"] = str(particion.month).zfill(2)\n",
    "    df[\"day\"] = str(particion.day).zfill(2)\n",
    "\n",
    "    wr.s3.to_parquet(\n",
    "        df=df,\n",
    "        path=\"s3://cchc-dw-dev-raw/_bolcon/insolvencias/\",\n",
    "        compression=\"gzip\",\n",
    "        partition_cols=[\"year\", \"month\", \"day\"],\n",
    "        mode=\"overwrite_partitions\",\n",
    "        dataset=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wr.s3.read_parquet(\"s3://cchc-dw-dev-raw/_bolcon/insolvencias/year=2023/month=02/day=03/\")\n",
    "staging = wr.s3.read_parquet(\"s3://cchc-dw-dev-staging/bolcon/insolvencias/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rut.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anterior = s3.get_object(Bucket=\"cchc-dw-qa-raw\", Key=\"boletin_concursal/insolvencia/01114390402146c5836f92357d21968a.gz.parquet\", VersionId=\"r4DGYAh4Hb3Ak2LwAS14pLXQ6zBhNbGv\")\n",
    "actual = s3.get_object(Bucket=\"cchc-dw-qa-raw\", Key=\"boletin_concursal/insolvencia/287a9570080c414baccf6a8244bb2ab6.gz.parquet\", VersionId=\"AzY86YBCKZ.BqM_0IX7XhPxpfIzLGRJx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anterior_df = pd.read_parquet(io.BytesIO(anterior[\"Body\"].read()))\n",
    "actual_df = pd.read_parquet(io.BytesIO(actual[\"Body\"].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partitions() -> list:\n",
    "    client = boto3.client(\"s3\")\n",
    "\n",
    "    response = client.list_objects(Bucket=f\"cchc-dw-dev-raw\", Prefix=f\"_bolcon/insolvencias/\")\n",
    "\n",
    "    p_keys = []\n",
    "    for k in response[\"Contents\"]:\n",
    "        p_keys.append(k[\"Key\"].split(\"/\")[2:-1])\n",
    "\n",
    "    return p_keys\n",
    "\n",
    "particiones = get_partitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_use = [datetime(int(x[0].split(\"=\")[1]),  int(x[1].split(\"=\")[1]), int(x[2].split(\"=\")[1])).date() for x in particiones]\n",
    "\n",
    "to_use = set(to_use)\n",
    "to_use = list(to_use)\n",
    "to_use.sort()\n",
    "to_use\n",
    "#to_use[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primera ejecución\n",
    "\n",
    "df = wr.s3.read_parquet(\"s3://cchc-dw-dev-raw/_bolcon/insolvencias/year=2022/month=11/day=07/\", dataset=True)\n",
    "df[\"fecha_publicacion\"] = pd.to_datetime(df.fecha_publicacion, format=\"%d/%m/%Y\")\n",
    "\n",
    "df[\"fecha_ejecucion\"] = pd.NA\n",
    "df[\"proceso_finalizado\"] = pd.NA\n",
    "\n",
    "wr.s3.to_parquet(\n",
    "    df=df,\n",
    "    path=\"s3://cchc-dw-dev-staging/boletin_concursal/insolvencias/\",\n",
    "    dataset=True,\n",
    "    mode=\"overwrite\",\n",
    "    table=\"bolcon_insolvencias_historico\",\n",
    "    database=\"staging_dev\",\n",
    "    schema_evolution=True,\n",
    "    dtype={\n",
    "        \"fecha_ejecucion\" : \"string\",\n",
    "        \"proceso_finalizado\" : \"boolean\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def staging(fecha: date):\n",
    "    _year, _month, _day = fecha.year, str(fecha.month).zfill(2), str(fecha.day).zfill(2)\n",
    "\n",
    "    nuevos_df = wr.s3.read_parquet(f\"s3://cchc-dw-dev-raw/_bolcon/insolvencias/year={_year}/month={_month}/day={_day}/\", dataset=True)\n",
    "    nuevos_df[\"fecha_publicacion\"] = pd.to_datetime(nuevos_df.fecha_publicacion, format=\"%d/%m/%Y\")\n",
    "\n",
    "    anterior_df = wr.s3.read_parquet(path)\n",
    "\n",
    "    ruts_anterior = anterior_df[anterior_df.proceso_finalizado.isnull()].rut.fillna(\"CORRECCION:\" + anterior_df.rol).drop_duplicates().to_list()\n",
    "    ruts_nuevos = nuevos_df.rut.fillna(\"CORRECCION:\" + nuevos_df.rol).drop_duplicates().to_list()\n",
    "\n",
    "\n",
    "    #Buscar los ruts en el dataframe antiguos que no existan en el nuevo dataframe para marcarlos como finalizados, o sea, ya no son insolventes\n",
    "    ruts_finalizados = [x for x in ruts_anterior if x not in ruts_nuevos]\n",
    "\n",
    "    anterior_df.loc[ anterior_df.rut.isin(ruts_finalizados), \"fecha_ejecucion\"] = fecha.strftime(\"%Y-%m-%d\")\n",
    "    anterior_df.loc[ anterior_df.rut.isin(ruts_finalizados),  \"proceso_finalizado\"] = True\n",
    "    \n",
    "    ruts_nuevos = [x for x in ruts_nuevos if x not in ruts_anterior]\n",
    "    nuevos_procesos = nuevos_df[nuevos_df.rut.fillna(\"CORRECCION:\" + nuevos_df.rol).isin(ruts_nuevos)].copy()\n",
    "\n",
    "    \n",
    "    df = pd.concat([anterior_df, nuevos_procesos])\n",
    "\n",
    "    print(\"Agregados\", len(ruts_nuevos), \"registros\")\n",
    "    print(ruts_nuevos)\n",
    "    print(\"Marcados\", len(ruts_finalizados), \"como finalizados\")\n",
    "\n",
    "    wr.s3.to_parquet(\n",
    "        df=df,\n",
    "        path=path,\n",
    "        dataset=True,\n",
    "        mode=\"overwrite\",\n",
    "        table=\"bolcon_insolvencias_historico\",\n",
    "        database=\"staging_dev\",\n",
    "        schema_evolution=True,\n",
    "        dtype={\n",
    "            \"fecha_ejecucion\" : \"string\",\n",
    "            \"proceso_finalizado\" : \"boolean\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "#staging(to_use[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for fecha in to_use[1:]:\n",
    "    clear_output(wait=True)\n",
    "    print(\"Ejecutando fecha\", fecha)\n",
    "    staging(fecha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = anterior_df.copy()\n",
    "df.rut = df.rut.fillna(\"CORRECCION:\" + df.rol)\n",
    "\n",
    "df[df.rol == 'C-18204-2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ver ruts del día actual que no están en el día anterior, por ende, están finalizado\n",
    "# 2. Ver ruts del día anterior que no estén en el actual, por ende, append\n",
    "ruts_anterior = anterior_df.rut.drop_duplicates().to_list()\n",
    "ruts_actuales = actual_df.rut.drop_duplicates().to_list()\n",
    "\n",
    "ruts_finalizados = [x for x in ruts_anterior if x not in ruts_actuales]\n",
    "\n",
    "procesos_finalizados = anterior_df[anterior_df.rut.isin(ruts_finalizados)][[\"rut\"]].drop_duplicates().copy()\n",
    "\n",
    "procesos_finalizados[\"fecha_ejecucion\"] = \"2023-02-03\"\n",
    "procesos_finalizados[\"proceso_finalizado\"] = True\n",
    "\n",
    "# Punto 2\n",
    "\n",
    "ruts_nuevos = [x for x in ruts_actuales if x not in ruts_anterior]\n",
    "\n",
    "nuevos_procesos = anterior_df[anterior_df.rut.isin(ruts_nuevos)].copy()\n",
    "\n",
    "\n",
    "# final = pd.concat([actual_df, procesos_finalizados])\n",
    "\n",
    "# final\n",
    "\n",
    "anterior_df.loc[anterior_df.rut.isin(ruts_finalizados), \"fecha_ejecucion\"] = \"2023-02-03\"\n",
    "anterior_df.loc[ anterior_df.rut.isin(ruts_finalizados),  \"proceso_finalizado\"] = True\n",
    "\n",
    "anterior_df[anterior_df.fecha_ejecucion.notnull()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
